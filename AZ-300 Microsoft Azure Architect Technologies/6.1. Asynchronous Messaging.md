# Asynchronous Messaging

## High-performance computing (HPC)

- Low-latency Remote Direct Memory Access (RDMA) networking
  - Low-latency network connection between the processing running on two servers or virtual machines in Azure.
  - It copies data from the network adapter directly to memory and avoids wasting CPU cycles.
  - For developers, it's seen like single machine with shared memory
- Usage: Installed on **head node** (must be Windows)
  - Server can manage **compute nodes** (can be Linux or Windows)
- How it works:
  - Uses Intel MPI library.
  - Some VMs (A8,A9 or ends with 'r') have network interface for RDMA
- Use-cases:
  - Burst to Azure from on-prem
  - molecular modeling and computational fluid dynamics
- In Azure:
  - H-series VMs

### Azure Batch

- PaaS for HPC
- Manages VMs, computes nodes with job scheduling (uses internal queue), autoscale, data persistence.
- Batch API lets you wrap existing (on-prem or cloud) compute node so it runs as a service on computer node pool that Batch manages.
- Good for intrinsically parallel (sometimes called **embarrassingly parallel** or **perfectly parallel**) workloads
  - Little to no effort to make application parallel because there's little to no dependencies between them
  - Image processing
- Integrates with **Azure Data Factory** (pipeline solution in Azure)
- Usage
  - Create Batch Account
  - In Batch account, create _pools_ of computer nodes (VMs)
  - In Batch account, create _job_ that runs basic _tasks_ on pool
    - A task is a CMD script

## Queues

- Split application into smaller modules with asynchronous messaging
  - Easy-to-manage in long term: Modules can be swapped/modified/updated without having to update the entire application.

### Message queues

- Queue = buffer that supports send & receive operations.
- Supports following cases:
  - Sender can send message to the queue
  - Receiver receives message from the queue
    - Message is removed.
  - Receiver examines (peeks at) the next available message
    - Message is not removed in the queue.
  - Many queues supports also returning the length of messages or if there's message left in queue to avoid blocking the receiver.
  - Many support transactions, leasing and visibility on top of it.
    - Leasing = concurrency lock
      - Message is unavailable to other receives while one receiver handles it.

### Concurrent queue consumers

- Does not block the business logic while requests are processed.
- Too many requests => consumer service is overflowed
  - Solution:
    - They need to be scaled out horizontally.
    - Only once instance should get the message
      - Load Balancer is needed to avoid one receiver becomes bottleneck
- In Azure: Azure Storage queues, Azure Service Bus queues.

### Implementation in code

#### Azure storage queues

- Send message

  ```c#
    CloudStorageAccount storageAccount = CloudStorageAccount.Parse(CloudConfigurationManager.GetSetting("StorageConnectionString"));
    CloudQueueClient queueClient = storageAccount.CreateCloudQueueClient();
    CloudQueue queue = queueClient.GetQueueReference("myqueue");
    queue.CreateIfNotExists();
    CloudQueueMessage message = new CloudQueueMessage("Hello, World");
    queue.AddMessage(message);
  ```

- Receive message
  - Peek: `CloudQueueMessage peekedMessage = queue.PeekMessage();`
  - Read & dequeue
    - Get message (message becomes invisible for 30 seconds):  `CloudQueueMessage retrievedMessage = queue.GetMessage();`
    - Delete message to dequeue: `retrievedMessage.DeleteMessage(retrievedMessage);`

#### Azure Service Bus

- Extends Azure Storage queues with middlewares, publish/subscribe messaging, load balancing, FIFO.
- Send batch to queue

  ```c#
    QueueClient queueClient = new QueueClient(ServiceBusConnectionString, QueueName);
    string messageBody = $"First Message";
    Message message = new Message(Encoding.UTF8.GetBytes(messageBody));
    await queueClient.SendAsync(message);
    var messages = new List<Message>();
    for (int i = 0; i < 10; i++)
    {
      var message = new Message(Encoding.UTF8.GetBytes($"Message {i:00}")};
      messages.Add(message);
    }
    await queueClient.SendBatchAsync(messages);
  ```

- Handle a message
  - In client SDK, you have handler callback you call either `CompleteAsync` or `AbandonAsync` (you receive the message again)

## WebHooks

- Polling => overallocating resource to check data.
- Use user-defined HTTP callbacks
- In azure functions you use it with Azure Functions.
  - `function.json` defines when the function is triggered.
  - Example for WebHooks

    ```json
      {
          "disabled":false,
          "bindings":[
              {
                  "authLevel":"function",
                  "name":"req",
                  "type":"httpTrigger",
                  "direction":"in",
                  "methods":[
                      "post"
                  ]
              },
              {
                  "name":"$return",
                  "type":"http",
                  "direction":"out"
              }
          ]
      }
    ```

  - Example for GitHub trigger

    ```json
      {
        "bindings":[
          {
            "type":"httpTrigger",
            "direction":"in",
            "webHookType":"github",
            "name":"req"
          },
          {
            "type":"http",
            "direction":"out",
            "name":"res"
          }
        ],
        "disabled":false
      }
    ```
